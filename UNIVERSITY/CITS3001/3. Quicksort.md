## In Place Sorting
CLRS defines an in place sorting algorithm as one that only a constant number of list elements are stored outside the list at any time. 
Insertion sort and heapsort are in place, but merge sort typically requires an O(N) buffer for merging and so is not in place.

## Stable Sorting
If any elements compare as being equal, there are multiple valid sorted orders. If there is no reason to swap them, we should not. We call sorting algorithms that maintain the relative order of equal elements stable. Insertion and merge sort are stable, heapsort is not. 

## Inversions
>An inversion in a list is any pair of elements i, j such that i appears before j in the list but j < i. 

Sorting can be thought of as the process of removing inversions from a list. In the worst case (reverse order) a list can contain O($N^2$) inversions. *Any algorithm which removes one inversion at a time (like insertion sort) can **never** be better than O($N^2$) in the worst case.*

## Partition
We aim to split the list into L and R such that there are no inversions between L and R. Therefore, everything in L must be <= everything in R. For some pivot element p, we could split the list such that L is everything <= p and R is everything > p. 
```python
# Partitions xs[lwr:upr] by xs[upr-1] and returns index of the pivot
def partition(xs: list, lwr: int, upr: int) -> int:
	# Select last element as pivot
	pivot = xs[upr-1]
	# Scan over list and swap any element <= pivot down
	mid = lwr
	for i in range(lwr, upr):
		if xs[i] <= pivot:
			xs[mid], xs[i] = xs[i], xs[mid]
			mid += 1
	# Pivot will have been last element swapped down
	return mid-1
```
## Quicksort
After partitioning, we have L stored in `xs[lwr:mid]` and R in `xs[mid+1:upr]`. There are *no* inversions between L and R, we just need to remove inversions within L and R. This can be done by sorting recursively. 
```python
# Sorts xs[lwr:upr]
# note: mid is actually mid - 1 (THANKS GOZZ)
def quicksort_range(xs: list, lwr: int, upr: int) -> None:
	# Only need to do anything if not trivially sorted
	if upr - lwr > 1:
		# Partition and get index of pivot
		mid = partition(xs, lwr, upr)
		# Recursively sort everything before pivot (exclusive)
		quicksort_range(xs, lwr, mid)
		# Recursively sort everything after pivot (exclusive)
		quicksort_range(xs, mid+1, upr)

def quicksort(xs: list) -> list:
	quicksort_range(xs, 0, len(xs))
	return xs
```
Partitioning takes linear time in the length of the range in the worst case, we pick the pivot that is already minimum or maximum. Therefore, O($N^2$). Typically, best case analysis is meaningless, however, the pivot ideally would be the mean, making the recursion depth O(lg N), where every element appears in one partition, so O(N lg N) total. 

## Is Quicksort "In Place"?
Quicksort only ever swaps elements within the list, so it is. *However*, quicksort requires additional memory for the function call stack. 

## Is Quicksort "Stable"?
Quicksort is stable *if* the partition is stable, however if the partition value is duplicated and it ends up swapping to the left, it is **NOT** stable. 
e.g.
$$ L_{1} \space \space \space L_{2} \space \space \space... L_{n} \space \space \space  y ... y ... x ... $$
- If $y=y$ or any on the right side equal $y$, this breaks stability.


## Quicksort Pivot Tips and Tricks and Tidbits
- Pivot choice matters a lot
- Always picking the last element means we can construct an "adversarial input"
- Pick a random pivot, better would be to pick multiple at random and using their median, lowering the likelihood of a bad pivot. 