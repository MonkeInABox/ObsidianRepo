## Distribution Sort
- Distribute the elements of the list into multiple intermediate data structures such that there are no inversions between blocks
- Sort each block
- Concatenate blocks

The simplest distribution sort is as follows:
- Assume we have some function `key()` that gives the block id element `x` should be put in such that `x < y` -> `key(x) < key(y)`
	- This means that any two elements in the same block are equal
	- Note that for integers we can just use the element itself
- Construct an empty list per block id
- Append each element into its block
- No need to sort each block as every element in each is equal
- Concatenate blocks
```python
def distribution_sort(xs: list, key=lambda x: x) -> list:
	# Prepare an empty list for each key
	k = max(map(key, xs)) + 1
	blocks = [[] for _ in range(k)]
	# Separate elements into their blocks
	for x in xs:
		blocks[key(x)].append(x)
	# Concatenate all blocks
	result = []
	for block in blocks:
		result.extend(block)
	return result
```
- With such a key function, distribution sort can sort any list in $O(N+k)$ time were $k$ is the number of blocks
- The challenge is finding a good key function

## Counting Sort
An optimised version of this simple distribution sort.
- Instead of actually separating elements into blocks immediately, we can count how many elements will end up in each block
- This is sufficient information to figure out what range of the output list each block will end up in
- No need to actually use an intermediate list, instead we can put each element directly into the appropriate range of the output list
- Therefore no need to concatenate blocks
```python
def counting_sort(xs: list, key=lambda x: x) -> list:
	# Count occurrences of each key
	k = max(map(key, xs)) + 1
	counts = [0] * k
	for x in xs:
		counts[key(x)] += 1
	# Cumulative sum of counts gives upper bounds of blocks
	for i in range(1, len(counts)):
		counts[i] += counts[i-1]
	# Use bounds to put each item in its spot directly
	result = [0] * len(xs)
	for x in reversed(xs):
		counts[key(x)] -= 1
		result[counts[key(x)]] = x
	return result
```
- $O(N+k)$

## Radix Sort 
- Let us consider the problem of sorting a list of large d-digit decimal integers
- Comparison-based sorting would require $\Omega(N lg N)$ 
- But each comparison can require $O(d)$ time, particularly for relatively close numbers
- So even with optimal comparison-based sorting this gives $O(dNlgN)$ time overall
- Naturally we might think to sort by the most significant (MSD) first
- This does work, but leaves us with blocks that need to be sorted recursively
- Let's instead sort by least significant digit (LSD) first
- We can now sort by next significant bit
```python
def radix_sort(xs: list[str]) -> list[str]:
	num_digits = max(map(len, xs))
	# Sort each digit starting from LSD
	for p in range(num_digits):
		# Typically counting sort, but any stable sort will do
		xs = counting_sort(xs, key=lambda x: get_digit(p, x))
	return xs
# Gets the power p digit from the digit string ds
def get_digit(p: int, ds: str) -> int:
	try:
		return int(ds[-p-1])
	except:
		return 0
```

## Bucket Sort
A distribution sort with the weaker key condition $x<y$ -> $key(x) <= key(y)$
- Given a range of values, cut that range up into b (typically equal) buckets
- Distribute elements into buckets by their bucket id
- Sort the elements in each bucket using some other algorithm
- Expected case $O(N)$ worst case $O(N^2)$
```python
# Bucket sort assuming elements in the range [lwr, upr)
def bucket_sort(xs: list[float], lwr=0.0, upr=1.0) -> list[float]:
	def key(x): return int(x * len(xs) / (upr - lwr))
	# Prepare an empty list for each bucket
	blocks = [[] for _ in xs]
	# Separate elements into their blocks
	for x in xs:
		blocks[key(x)].append(x)
	# Sort and concatenate all blocks
	result = []
	for block in blocks:
		block.sort()
		result.extend(block)
	return result
```