One of the most widely used greedy strategies. 
- Usually encode data in fixed size chunks:
	- ASCII are 7 bits
	- Integers are 32 bits
- To represent $X$ different symbols, a fixed length code requires $\lceil lgX \rceil$ bits
	- Each bit at best lets us split the rest of the symbols in half
- Using a fixed length code, encoding a sequence of $N$ elements requires $N\lceil lgX \rceil$ bits

## Example
"streets are stone stars are hot"
- 9 characters required, our fixed length code must be at least $\lceil lg9 \rceil = 4$ bits per character
- Encoding this 31 character string at 4 bits per character requires 124 bits

## Compression
- Variable length codes
- Some symbols appear more than others, more common symbols should be shorter
- Aim for a prefix free code, no codeword is a prefix of another so we can concatenate without ambiguity
- Therefore, greedy algorithm for constructing a binary tree representing a variable length code for an alphabet
	- Start with one leaf vertex per symbol, with weight of the frequency
	- Select the two smallest symbols, and join them using a new parent to get a binary tree with their combined weight
	- Repeat, joining subtrees until we have a single tree containing all symbols
	- The path then corresponds to the code for each symbol

## Proof
- In any binary tree, the sibling of a deepest leaf must be a deepest leaf, otherwise one of its descendants will be the a deeper leaf
- If $x$ and $y$ are the least common symbols, swapping them to the deepest siblings cannot make the code less efficient
- If we replace $x$ and $y$ with $z$, the sum of frequencies, we get a subproblem, each occurrence of $z$ will be one bit cheaper than the original $x$ or $y$
- We can re-expand $z$ at the cost of one extra bit per occurrence of $x$ or $y$, exactly offsetting the amount we saved by merging them. It was optimal, so it is not possible to get a better solution to the subproblem. 